{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 494/594\n",
    "## Setting up a Basic Network\n",
    "\n",
    "We begin by using the iPython `%load` magic to import some libraries and set some styling (to make our plots look nice) from `/.include/header.py`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load ./include/header.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate a 3x3 picture and visualize\n",
    "\n",
    "For now, don't worry about the code used to generate the image of the rectangular grid.  (**Bonus points** if you can come up with a fancier/more compact solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "N0 = L*L\n",
    "x = [0,0,0,1,1,0,1,1,0]\n",
    "\n",
    "# Print the input image:\n",
    "image = ''.join([ci if (i+1)%L else ci+'\\n' for i,ci in \n",
    "                 enumerate([' ▉ ' if cx else ' ░ ' for i,cx in enumerate(x)])])\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the first hidden layer and initialize weights and biases to random values\n",
    "\n",
    "We are using the `random` submodule of the `numpy` module to generate arrays of uniformly distributed random numbers between the upper and lower bounds with shapes given by `size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N0 = 9 # number of neurons in the input layer\n",
    "N1 = 2 # number of neurons in the hidden layer\n",
    "\n",
    "# here w is a N1 x N0 matrix and b is a N1 x 1 vector\n",
    "w1 = np.random.uniform(low=-10,high=10,size=(N1,N0))\n",
    "b1 = np.random.uniform(low=-1,high=1, size=N1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span alert alert-warning\">\n",
    "    Note the dimensions of the weight matrix is N<sub>1</sub> x N<sub>0</sub>, while the bias vector has N<sub>1</sub> elements.\n",
    "</div>\n",
    "\n",
    "<!--ml4s.draw_network([N0,N1], node_labels=[x,[f'$\\sigma(z^1_{i})$' for i in range(N1)]],weights=[w1], biases=[b1]) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'b¹ = {b1}\\n')\n",
    "print(f'w¹ =\\n {w1}\\n')\n",
    "print(f'x/aᵒ = {x}\\n')\n",
    "\n",
    "ml4s.draw_network([N0,N1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate at the first hidden layer\n",
    "\n",
    "\\begin{equation}\n",
    "z = \\mathsf{w} \\cdot \\vec{x} + \\vec{b}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.dot(w1,x)+b1\n",
    "print(f'z¹ = {z1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the sigmoid neuron and evaluate the non-linearity on the first hidden layer\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(z) = \\frac{1}{1+\\mathrm{e}^{-z}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def σ(z):\n",
    "    return 1.0/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = σ(z1)\n",
    "print(f'a¹ = {a1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are define the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = 1\n",
    "w2 = np.random.uniform(low=-10,high=10,size=(N2,N1))\n",
    "b2 = np.random.uniform(low=-1,high=1, size=N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'b² = {b2}\\n')\n",
    "print(f'w² =\\n {w2}\\n')\n",
    "print(f'a¹ = {a1}\\n')\n",
    "\n",
    "ml4s.draw_network([N0,N1,N2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate (feed forward) the last step to the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = np.dot(w2,a1)+b2\n",
    "a2 = σ(z2)\n",
    "print(f'a² = {a2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the weights and biases for the entire network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'a² = {a2}')\n",
    "print(f'b² = {b2}\\n')\n",
    "print(f'w² =\\n {w2}\\n')\n",
    "print(f'a¹ = {a1}\\n')\n",
    "print(f'b¹ = {b1}\\n')\n",
    "print(f'w¹ =\\n {w1}\\n')\n",
    "print(f'x/aᵒ = {x}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final (activation) value of a² tells us whether or not we have a rectangle in our picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml4s.draw_network([N0,N1,N2],node_labels=[x,a1,a2],weights=[w1,w2], biases=[b1,b2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
